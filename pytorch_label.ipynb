{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torch.jit import ScriptModule\n",
    "from torchvision.transforms import Compose, InterpolationMode, Resize, CenterCrop, ToTensor, Normalize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from labels.labels import IMAGENET_1K, IMAGENET_21K\n",
    "\n",
    "\n",
    "# !wget -O \"../../labels/ImageNetLabels.txt\" https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\n",
    "# !wget -O \"../../labels/imagenet21k_wordnet_lemmas.txt\" https://storage.googleapis.com/bit_models/imagenet21k_wordnet_lemmas.txt\n",
    "\n",
    "class LogConstants(Enum):\n",
    "    FMT = '%(asctime)s.%(msecs)03d %(levelname)s:\\t%(message)s'\n",
    "    DT_FMT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "if not os.path.exists('logs'): os.makedirs('logs')\n",
    "logging.basicConfig(\n",
    "    filename=f'logs/tested_models.log',\n",
    "    filemode='a',\n",
    "    level=logging.INFO,\n",
    "    format=LogConstants.FMT.value,\n",
    "    datefmt=LogConstants.DT_FMT.value)\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(fmt=LogConstants.FMT.value,\n",
    "                              datefmt=LogConstants.DT_FMT.value)\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(console)\n",
    "\n",
    "[print(device := 'cuda:0') if torch.cuda.is_available() else print(device := 'cpu')]\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "IMAGE_FILES_PATH = Path('../../data/images/')\n",
    "LABELS_PATH = Path('../../labels/')\n",
    "\n",
    "\n",
    "# timm.list_models('*21k*')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def run(model: ScriptModule,\n",
    "        filename: Path,\n",
    "        classes: dict,\n",
    "        target_classes: set,\n",
    "        torchscript: bool,\n",
    "        input_dim: Optional[int] = 224) -> None:\n",
    "    transform = Compose([\n",
    "        Resize(input_dim, InterpolationMode.LANCZOS),\n",
    "        CenterCrop(input_dim),\n",
    "        ToTensor(),\n",
    "        Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "    ])\n",
    "    img = transform(Image.open(filename))[None,] if torchscript else transform(Image.open(filename))[None,].to(device)\n",
    "    probs = model(img)\n",
    "    top_pred = torch.argmax(probs)\n",
    "    pred_label = classes[top_pred.item()]\n",
    "    if pred_label in target_classes:\n",
    "        pred_label = Path(re.sub('[\\W\\s]+', '_', pred_label.split(',')[0]))\n",
    "        try:\n",
    "            (filename.parent / pred_label).mkdir()\n",
    "        except FileExistsError:\n",
    "            ...\n",
    "        filename.rename(filename.parent / pred_label / filename.name)\n",
    "\n",
    "\n",
    "def label(model: ScriptModule,\n",
    "          root_dir: Path,\n",
    "          class_map: dict,\n",
    "          n_jobs: Optional[int] = -1,\n",
    "          target_classes: Optional[str] = '',\n",
    "          parallel: Optional[bool] = False,\n",
    "          torchscript: Optional[bool] = False,\n",
    "          input_dim: Optional[int] = 224) -> None:\n",
    "    images = [d for d in Path(root_dir).iterdir() if not d.is_dir()]\n",
    "    target_classes = set(Path(target_classes).read_text().splitlines()) if target_classes else class_map.values()\n",
    "    if parallel:\n",
    "        Parallel(n_jobs=n_jobs, prefer='threads')(\n",
    "            delayed(run)(model, img, class_map, target_classes, torchscript, input_dim) for img in\n",
    "            tqdm(images, total=len(images)))\n",
    "    else:\n",
    "        [run(model, img, class_map, target_classes, torchscript, input_dim) for img in tqdm(images, total=len(images))]\n",
    "\n",
    "\n",
    "def unlabel(root_dir: str) -> None:\n",
    "    dirs = [p.iterdir() for p in Path(root_dir).iterdir() if p.is_dir()]\n",
    "    [f.rename(f.parent.parent / f.name) for d in dirs for f in d]\n",
    "    [shutil.rmtree(p) for p in Path(root_dir).iterdir() if p.is_dir()]\n",
    "\n",
    "\n",
    "def targets_found() -> dict:\n",
    "    found = {d for d in Path(IMAGE_FILES_PATH).iterdir() if d.is_dir()}\n",
    "    return {d.name: len(set(d.iterdir())) for d in sorted(found)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a single model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load built-in model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# model = models.efficientnet_b7(pretrained=True).to(device).eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load `timm` model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'regnetz_e8'\n",
    "# model = timm.create_model(MODEL_NAME, pretrained=True).to(device).eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load scripted/quantized model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'vit_base_patch8_224_scripted_quantized.pt'\n",
    "# model = torch.jit.load(MODEL_NAME).eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load multiple models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample 1K Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "for m in [\n",
    "    'cait_s24_384',\n",
    "    # 'regnetz_e8',\n",
    "    # 'vit_base_patch16_384',\n",
    "    # 'vit_base_patch8_224'\n",
    "]:\n",
    "    model = timm.create_model(m, pretrained=True)\n",
    "    label(model.to(device).eval(), IMAGE_FILES_PATH, IMAGENET_1K, input_dim=384, target_classes='target_classes.txt')\n",
    "    logging.info({m: targets_found()})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# unlabel(IMAGE_FILES_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample 21K Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 'mixer_l16_224_in21k' ## keeps downloading\n",
    "for m in [\n",
    "    # 'resnetv2_101x1_bitm_in21k',\n",
    "    # 'resnetv2_50x3_bitm_in21k',\n",
    "    # 'resnetv2_50x1_bitm_in21k',\n",
    "    # 'vit_base_patch8_224_in21k',\n",
    "    # 'vit_small_r26_s32_224_in21k',\n",
    "    # 'vit_base_patch16_224_in21k',\n",
    "    # 'vit_tiny_patch16_224_in21k',\n",
    "    # 'vit_tiny_r_s16_p8_224_in21k',\n",
    "    'vit_small_patch32_224_in21k',\n",
    "    # 'vit_base_patch32_224_in21k',\n",
    "    # 'vit_small_patch16_224_in21k'\n",
    "]:\n",
    "    model = timm.create_model(m, pretrained=True)\n",
    "    label(model.to(device).eval(), IMAGE_FILES_PATH, IMAGENET_21K, target_classes='target_classes.txt')\n",
    "    logging.info({m: targets_found()})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# unlabel(IMAGE_FILES_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}